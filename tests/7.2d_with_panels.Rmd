---
title: "Integration test for MRSea 2d salsa with other variables, with 1d smooth, with panels, no interactions"
author: "LAS Scott-Hayward, C Fell"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---


-------

```{r echo=FALSE, message=FALSE, warning=FALSE}
# devtools::install_github("lindesaysh/MRSea")
devtools::load_all("C:/Users/kryzi/OneDrive - University of St Andrews/PhD/Code/MRsea")
# require(MRSea)
require(tidyverse)
require(patchwork)
require(knitr)
require(MuMIn)
knitr::opts_chunk$set(fig=TRUE, warning=FALSE, message=FALSE, eval=TRUE, comment = '')
```

## Introduction
This is the seventh in a series of tests that can be used to check changes to the MRSea package do not break previously working elements. They replicate the case study in the vignette but broken down into chunks. This seventh one checks the 2D salsa functions with other variables, with a 1d smooth, with panels and no interactions.

```{r message=FALSE, warning=FALSE}
count.data <- read.csv("1.count.data.csv")
data <- count.data
data$response <- round(data$NHAT)
data$blockid <- paste(data$transect.id, data$season, data$impact,sep = "")
attach(data)
```

## Set up

Set a prediction grid.  

```{r, echo=FALSE}
data("nysted.predictdata")  # contains predict.data
# This is a spatial grid for making predictions.  All covariates in 
# final model must be in this data frame and the naming must be the 
# same as for the data
predictData <- nysted.predictdata

# Not including impact or season in the model so included data for only one impact and season, impact = 1 and season = 1 has highest count
predictData <- predictData[predictData$impact==1&predictData$season==1,]

```

Set up the initial model with factor covariates and offset term
```{r message=FALSE}
initialModel <- glm(response ~ 1 + offset(log(area)), family = "quasipoisson", data = data)

```


```{r }

salsa1dlist <- list(
  fitnessMeasure = "cv.gamMRSea", 
  minKnots_1d = 2,
  maxKnots_1d = 5, 
  startKnots_1d = 1, 
  degree = 2, 
  maxIterations = 10, 
  gaps = c(0), 
  cv.opts=list(cv.gamMRSea.seed=1, K=10)
)

```


```{r message=FALSE, warning=FALSE, results='hide'}
# run SALSA
set.seed(1234)
salsa1dOutput <- runSALSA1D(initialModel, salsa1dlist, c("depth"), predictionData=predictData, datain=data, removal=TRUE, panelid = data$blockid)
```

```{r, echo=FALSE, results='asis' }
# How many knots were chosen for depth?
depth_knots <- salsa1dOutput$splineParams[[2]]$knots
# ~~~~~~~~~~~~~~~~~~~~~~~

cat("Number of knots selected for depth:", length(depth_knots), "this should be 1. \n\n")
cat("Location of knot selected for depth:", round(depth_knots, 4), "this should be -12.212. \n\n")

```

## Selection of flexibility for 2D smooth term

Create a grid of knots that will be used as possible knot locations.


```{r knotgrid, message=FALSE, fig=TRUE, fig.align='center', fig.width=9, fig.height=6, cache=TRUE}

knotgrid <- read.csv("4.knotgrid.csv")

```

```{r knot_comp, echo=FALSE, results='asis'}

cat("Sum of knotgrid:", sum(knotgrid), "this should be 2018630. \n\n")

```


```{r, echo=FALSE}
# make distance matrices for datatoknots and knottoknots
distMats <- makeDists(cbind(data$x.pos, data$y.pos), knotgrid)

# ~~~~~~~~~~~~~~~~~~~~~~~

```


```{r dist_comp, echo=FALSE, results='asis'}

cat("Sum of datadist:", sum(distMats$dataDist[1,]), "this should be 8224.849. \n\n")
cat("Sum of knotdist:", sum(distMats$knotDist), "this should be 1775357. \n\n")

```

Set Salsa2D parameters.

```{r}

# make parameter set for running salsa2d
salsa2dlist<-list(
  fitnessMeasure = 'cv.gamMRSea', 
  knotgrid = knotgrid, 
  startKnots=5, 
  minKnots=4, 
  maxKnots=12, 
  gap=0, 
  cv.opts=list(cv.gamMRSea.seed=1, K=10)
)
```


Run SALSA2D to find the appropriate number and location of knots for the 2D smooth term of `x.pos` and `y.pos`.

```{r message=FALSE, warning=FALSE, results='hide'}

start_time <- Sys.time()
salsa2dOutput<-runSALSA2D(salsa1dOutput$bestModel, salsa2dlist, d2k=distMats$dataDist, k2k=distMats$knotDist, panels = data$blockid)
total_time <- Sys.time() - start_time

```


## Predictions compared to original

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.width=7.5}

predictdistMats <- makeDists(cbind(predictData$x.pos, predictData$y.pos), knotgrid)

preds_out <- predict(object=salsa2dOutput$bestModel, newdata=predictData, type='response', g2k=predictdistMats$dataDist)

pred_resp <- ggplot() + stat_summary_2d(data=predictData, aes(predictData$x.pos, predictData$y.pos, z=preds_out), fun=max, binwidth=c(0.5,0.5)) + theme_bw() + scale_fill_distiller(palette = "Spectral", name="Animal Counts", limit=c(0, 8.6)) + coord_fixed(ratio = 1) + xlab("X coordinate") + ylab("Y coordinate") + ggtitle("New predictions")

knot_pos <- salsa2dOutput$splineParams[[1]]$knotPos
knot_loc <- knotgrid[knot_pos,]
colnames(knot_loc) <- c("xx", "yy")
rad_pos <- salsa2dOutput$splineParams[[1]]$radiusIndices
knot_loc$rad <- salsa2dOutput$splineParams[[1]]$radii[rad_pos]

for (rr in 1:nrow(knot_loc)) {
  pred_resp <- pred_resp + annotate("path", x=knot_loc$xx[rr] + 0.5 * cos(seq(0,2*pi,length.out=100)), y=knot_loc$yy[rr] + 0.5 * sin(seq(0,2*pi,length.out=100)))
}

predict_read_in <- read.csv("7.predict.data.csv")

resp_read <- ggplot() + stat_summary_2d(data=predict_read_in, aes(x.pos, y.pos, z=ResponsePredictions), fun=max, binwidth=c(0.5,0.5)) + theme_bw() + scale_fill_distiller(palette = "Spectral", name="Animal Counts", limit=c(0, 8.6)) + coord_fixed(ratio = 1) + xlab("X coordinate") + ylab("Y coordinate") + ggtitle("Saved predictions")

knot_loc_read <- read.csv("7.knot.loc.csv")

for (rr in 1:nrow(knot_loc)) {
  resp_read <- resp_read + annotate("path", x=knot_loc_read$xx[rr] + 0.5 * cos(seq(0,2*pi,length.out=100)), y=knot_loc_read$yy[rr] + 0.5 * sin(seq(0,2*pi,length.out=100)))
}

(pred_resp + resp_read) + plot_layout(guides = 'collect')

```



```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.width=7.5}

preds_out_link <- predict(object=salsa2dOutput$bestModel, newdata=predictData, type='link', g2k=predictdistMats$dataDist)

pred_link <- ggplot() + stat_summary_2d(data=predictData, aes(predictData$x.pos, predictData$y.pos, z=preds_out_link), fun=max, binwidth=c(0.5,0.5)) + theme_bw() + scale_fill_distiller(palette = "Spectral", name="Nhat on link scale", limit=c(-9.6, 3.6)) + coord_fixed(ratio = 1) + xlab("X coordinate") + ylab("Y coordinate") + ggtitle("New predictions")

for (rr in 1:nrow(knot_loc)) {
  pred_link <- pred_link + annotate("path", x=knot_loc$xx[rr] + 0.5 * cos(seq(0,2*pi,length.out=100)), y=knot_loc$yy[rr] + 0.5 * sin(seq(0,2*pi,length.out=100)))
}

link_read <- ggplot() + stat_summary_2d(data=predict_read_in, aes(x.pos, y.pos, z=LinkPredictions), fun=max, binwidth=c(0.5,0.5)) + theme_bw() + scale_fill_distiller(palette = "Spectral", name="Nhat on link scale", limit=c(-9.6, 3.6)) + coord_fixed(ratio = 1) + xlab("X coordinate") + ylab("Y coordinate") + ggtitle("Saved predictions")

for (rr in 1:nrow(knot_loc)) {
  link_read <- link_read + annotate("path", x=knot_loc_read$xx[rr] + 0.5 * cos(seq(0,2*pi,length.out=100)), y=knot_loc_read$yy[rr] + 0.5 * sin(seq(0,2*pi,length.out=100)))
}

pred_link + link_read + plot_layout(guides = 'collect')

```




```{r pred_compare, echo=FALSE, results='asis'}

cat("Sum of all predictions on response scale:", sum(preds_out), "this should be 2201.378. \n\n")

cat("Sum of all predictions on link scale:", sum(preds_out_link), "this should be -7843.877. \n\n")

cat("Time for training:", total_time) #18.93416

```


```{r, echo=FALSE}
sum_results <- summary(salsa2dOutput$bestModel)
kable(sum_results$coefficients, digits=3, caption="New coefficients")

```


```{r, echo=FALSE}
sum_results_read_in <- read.csv("7.sum.results.csv")
kable(sum_results_read_in, digits=3, caption="Saved coefficients")

```



```{r sum_compare, echo=FALSE, results='asis'}

cat("Sum of all estimates:", sum(sum_results$coefficients[,1]), "this should be -4.674224. \n\n")

cat("Sum of all robust SE:", sum(sum_results$coefficients[,3]), "this should be 35.28362. \n\n")

cat("Standard errors are not equal to robust standard errors:", sum(sum_results$coefficients[,2])!=sum(sum_results$coefficients[,3]), "\n\n")

cat("Dispersion:", sum_results$dispersion, "this should be 25.57402. \n\n")

```


```{r mean_sum_sq, echo=FALSE, results='asis'}

mean_sum_sq <- sum((predictData$truth.re - preds_out)^2)/nrow(predictData)

cat("Mean square error:", mean_sum_sq, "this should be 0.4363444. \n\n")

```



