---
title: "Integration test for 1d salsa without panels"
author: "LAS Scott-Hayward, C Fell"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---


-------

```{r echo=FALSE, message=FALSE, warning=FALSE}
devtools::load_all("C:/Users/kryzi/OneDrive - University of St Andrews/PhD/Code/MRsea")
# require(MRSea)
require(tidyverse)
require(patchwork)
require(knitr)
require(MuMIn)
knitr::opts_chunk$set(fig=TRUE, warning=FALSE, message=FALSE, eval=TRUE, comment = '')
```

# MRSea Integration test - 1d no panels

## Introduction
This is the second in a series of tests that can be used to check changes to the MRSea package do not break previously working elements. They replicate the case study in the vignette but broken down into chunks. This second one checks the 1D salsa functions without a panel structure.

In the vignette models in sections 3 & 4 use glm from mgcv, we are interested in testing MRSea so don't care about testing mgcv so will omit those models. 

```{r message=FALSE, warning=FALSE}
count.data <- read.csv("1.count.data.csv")
data <- count.data
data$response <- round(data$NHAT)
attach(data)
```

## Selection of 1D Covariates

Specify the parameters required:

```{r }

salsa1dlist <- list(
  fitnessMeasure = "cv.gamMRSea", 
  minKnots_1d = 2,
  maxKnots_1d = 5, 
  startKnots_1d = 1, 
  degree = 2, 
  maxIterations = 10, 
  gaps = c(0), 
  cv.opts=list(cv.gamMRSea.seed=1, K=10)
)

```

Set a prediction grid.  

```{r, echo=FALSE}
data("nysted.predictdata")  # contains predict.data
# This is a spatial grid for making predictions.  All covariates in 
# final model must be in this data frame and the naming must be the 
# same as for the data
predictData <- nysted.predictdata

# Not including impact or season in the model so included data for only one impact and season, impact = 1 and season = 1 has highest count
predictData <- predictData[predictData$impact==1&predictData$season==1,]

```

Set up the initial model with factor covariates and offset term
```{r message=FALSE}
initialModel <- glm(response ~ 1 + offset(log(area)), family = "quasipoisson", data = data)

```


```{r message=FALSE, warning=FALSE, results='hide'}
# run SALSA
set.seed(1234)
salsa1dOutput <- runSALSA1D(initialModel, salsa1dlist, c("depth"), predictionData=predictData, datain=data, removal=TRUE)

```

```{r, echo=FALSE, results='asis' }
# How many knots were chosen for depth?
depth_knots <- salsa1dOutput$splineParams[[2]]$knots
# ~~~~~~~~~~~~~~~~~~~~~~~

cat("Number of knots selected for depth:", length(depth_knots), "this should be 1. \n\n")
cat("Location of knot selected for depth:", round(depth_knots, 4), "this should be -12.212. \n\n")

```

## Predictions compared to original

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.width=7.5}

preds_out <- predict(object=salsa1dOutput$bestModel, newdata=predictData, type='response')

pred_resp <- ggplot() + stat_summary_2d(data=predictData, aes(predictData$x.pos, predictData$y.pos, z=preds_out), fun=max, binwidth=c(0.5,0.5)) + theme_bw() + scale_fill_distiller(palette = "Spectral", name="Animal Counts", limit=c(0, 1.4)) + coord_fixed(ratio = 1) + xlab("X coordinate") + ylab("Y coordinate") + ggtitle("New Predictions")

predict_read_in <- read.csv("2.predict.data.csv")

resp_read <- ggplot() + stat_summary_2d(data=predict_read_in, aes(x.pos, y.pos, z=ResponsePredictions), fun=max, binwidth=c(0.5,0.5)) + theme_bw() + scale_fill_distiller(palette = "Spectral", name="Animal Counts", limit=c(0, 1.4)) + coord_fixed(ratio = 1) + xlab("X coordinate") + ylab("Y coordinate") + ggtitle("Saved Predictions")

(pred_resp + resp_read) + plot_layout(guides = 'collect')

```


```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.width=7.5}

preds_out_link <- predict(object=salsa1dOutput$bestModel, newdata=predictData, type='link')

pred_link <- ggplot() + stat_summary_2d(data=predictData, aes(predictData$x.pos, predictData$y.pos, z=preds_out_link), fun=max, binwidth=c(0.5,0.5)) + theme_bw() + scale_fill_distiller(palette = "Spectral", name="Nhat on link scale", limit=c(-13, 2.5)) + coord_fixed(ratio = 1) + xlab("X coordinate") + ylab("Y coordinate")  + ggtitle("New Predictions")

link_read <- ggplot() + stat_summary_2d(data=predict_read_in, aes(x.pos, y.pos, z=LinkPredictions), fun=max, binwidth=c(0.5,0.5)) + theme_bw() + scale_fill_distiller(palette = "Spectral", name="Nhat on link scale", limit=c(-13, 2.5)) + coord_fixed(ratio = 1) + xlab("X coordinate") + ylab("Y coordinate")  + ggtitle("Saved Predictions")

pred_link + link_read + plot_layout(guides = 'collect')

```




```{r pred_compare, echo=FALSE, results='asis'}

cat("Sum of all predictions on response scale:", sum(preds_out), "this should be 2170.705. \n\n")

cat("Sum of all predictions on link scale:", sum(preds_out_link), "this should be -5597.669. \n\n")

```




```{r, echo=F}
sum_results <- summary(salsa1dOutput$bestModel)
kable(sum_results$coefficients, digits=3, caption="coefficients for new model")

sum_results_read_in <- read.csv("2.sum.results.csv")
kable(sum_results_read_in, digits=3, caption="saved model coefficients")

```
    
     

```{r sum_compare, echo=FALSE, results='asis'}

cat("Sum of all estimates:", sum(sum_results$coefficients[,1]), "this should be 21.24178. \n\n")

cat("Sum of all robust SE:", sum(sum_results$coefficients[,3]), "this should be 32.22634. \n\n")

cat("Standard errors are equal to robust standard errors:", sum(sum_results$coefficients[,2])==sum(sum_results$coefficients[,3]), "\n\n")

cat("Dispersion:", sum_results$dispersion, "this should be 36.45296. \n\n")

```

```{r mean_sum_sq, echo=FALSE, results='asis'}

mean_sum_sq <- sum((predictData$truth.re - preds_out)^2)/nrow(predictData)

cat("Mean square error:", mean_sum_sq, "this should be 1.270456. \n\n")

```



